{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "requirements:\n",
    "beautifulsoup4\n",
    "lxml\n",
    "tensorflow\n",
    "numpy\n",
    "pandas\n",
    "emoji\n",
    "selenium\n",
    "\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Attention,Bidirectional,Dense,Embedding,LSTM,GRU\n",
    "from tensorflow.keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas=pd.read_csv('data/stephenasmith_sa.csv.gz',compression='gzip')\n",
    "max_tweet_len=50\n",
    "embedding_size=100\n",
    "sas['y']=1*(sas['std_favorite_count']>-0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_map(path):\n",
    "    M={}\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            line_list=line.split()\n",
    "            word=line_list[0]\n",
    "            M[word]=np.array([float(val) for val in line_list[1:]])\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M=get_embedding_map('glove/glove.twitter.27B.{}d.txt'.format(embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=10000\n",
    "tokenizer=Tokenizer(num_words=vocab_size,\n",
    "                    filters='!\"$%&()*+,-./:;=?[\\\\]^_`{|}~\\t\\n',\n",
    "                    oov_token='<unk>')\n",
    "tokenizer.fit_on_texts(sas['full_text'])\n",
    "sequences=tokenizer.texts_to_sequences(sas['full_text'])\n",
    "data=pad_sequences(sequences,maxlen=max_tweet_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "E=np.zeros((vocab_size,embedding_size))\n",
    "for word,index in tokenizer.word_index.items():\n",
    "    if index>vocab_size-1:\n",
    "        break\n",
    "    else:\n",
    "        if word in M:\n",
    "            E[index]=M[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m=tf.keras.models.Sequential([\n",
    "#     Embedding(vocab_size,\n",
    "#               embedding_size,\n",
    "#               embeddings_initializer=Constant(E),\n",
    "#               input_length=max_tweet_len,\n",
    "#               trainable=False),\n",
    "#     tf.keras.layers.GRU(128,return_sequences=True,activation='relu'),\n",
    "#     tf.keras.layers.GRU(128,activation='relu'),\n",
    "#     tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# m.compile(loss='binary_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),metrics=[tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m=tf.keras.models.Sequential([\n",
    "    Embedding(vocab_size,\n",
    "              embedding_size,\n",
    "              embeddings_initializer=Constant(E),\n",
    "              input_length=max_tweet_len,\n",
    "              trainable=True),\n",
    "    Bidirectional(LSTM(256,activation='relu',dropout=0.2)),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "m.compile(loss='binary_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28992 samples, validate on 7249 samples\n",
      "Epoch 1/10\n",
      "28992/28992 [==============================] - 41s 1ms/sample - loss: 0.7195 - accuracy: 0.5801 - val_loss: 1.1212 - val_accuracy: 0.5620\n",
      "Epoch 2/10\n",
      "28992/28992 [==============================] - 38s 1ms/sample - loss: 0.6053 - accuracy: 0.6691 - val_loss: 0.7243 - val_accuracy: 0.5569\n",
      "Epoch 3/10\n",
      "28992/28992 [==============================] - 38s 1ms/sample - loss: 0.5175 - accuracy: 0.7334 - val_loss: 0.7548 - val_accuracy: 0.5475\n",
      "Epoch 4/10\n",
      "28992/28992 [==============================] - 38s 1ms/sample - loss: 0.4682 - accuracy: 0.7627 - val_loss: 0.6210 - val_accuracy: 0.6766\n",
      "Epoch 5/10\n",
      "28992/28992 [==============================] - 38s 1ms/sample - loss: 0.4325 - accuracy: 0.7838 - val_loss: 0.7576 - val_accuracy: 0.5955\n",
      "Epoch 6/10\n",
      "28992/28992 [==============================] - 38s 1ms/sample - loss: 0.4556 - accuracy: 0.7995 - val_loss: 0.7200 - val_accuracy: 0.6506\n",
      "Epoch 7/10\n",
      "28992/28992 [==============================] - 39s 1ms/sample - loss: 0.3789 - accuracy: 0.8125 - val_loss: 0.7818 - val_accuracy: 0.6397\n",
      "Epoch 8/10\n",
      "28992/28992 [==============================] - 38s 1ms/sample - loss: 0.3577 - accuracy: 0.8230 - val_loss: 0.9035 - val_accuracy: 0.5986\n",
      "Epoch 9/10\n",
      "28992/28992 [==============================] - 39s 1ms/sample - loss: 0.3337 - accuracy: 0.8355 - val_loss: 1.0616 - val_accuracy: 0.6067\n",
      "Epoch 10/10\n",
      "28992/28992 [==============================] - 38s 1ms/sample - loss: 0.3148 - accuracy: 0.8451 - val_loss: 1.1941 - val_accuracy: 0.6004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f98a0563d50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(data,sas['y'].values,\n",
    "      batch_size=32,\n",
    "      epochs=10,\n",
    "      validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test='Btw    Ass  Damn and hell are allowed on my page  Thats mild  generic profanity  Nothing else '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_score(text):\n",
    "    X_new=pad_sequences(tokenizer.texts_to_sequences([text]),maxlen=max_tweet_len)\n",
    "    return m.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999908]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_score(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9134425]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_score('thanks brother man I am grateful my dude mild profanity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt=pd.read_csv('data/stephenasmith.csv.gz',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012    2984\n",
       "2013    2642\n",
       "2018    2599\n",
       "2016    2444\n",
       "2015    1900\n",
       "2011    1575\n",
       "2014    1469\n",
       "2017    1363\n",
       "2019    1157\n",
       "2010     868\n",
       "2009     509\n",
       "Name: created_year, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt['created_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19231163505894414"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tt['std_favorite_count']>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('scoring_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=tf.keras.models.load_model('scoring_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpt2_output=pd.read_csv('gpt-2_output/gpt2_gentext_20191123_053641_temp1.0.txt',sep='\\n',header=None)\n",
    "def strip_tags(tweet):\n",
    "    tweet=tweet.replace('<|startoftext|>','')\n",
    "    tweet=tweet.replace('<|endoftext|>','')\n",
    "    \n",
    "    return tweet\n",
    "generated_tweets=[strip_tags(tweet[0]) for tweet in gpt2_output.values if tweet[0]!='====================']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_score(text_list):\n",
    "    X_new=pad_sequences(tokenizer.texts_to_sequences(text_list),maxlen=max_tweet_len)\n",
    "    return m.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring=pd.DataFrame({'tweet':generated_tweets,'score':[s[0] for s in predict_score(generated_tweets)]})\n",
    "top_100=scoring.sort_values('score',ascending=False).iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>When Jesus Missing in Samoa, neither HBCU, col...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>I'm about to appear on REGRET radio ppl. Call ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>Jesus. Cowboys have the best offense in footba...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>Oh God, Oh Jesus Do I Sound So sad. This is li...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>I wanted &lt;at&gt;TinyQuinn to win the Heisman befo...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Haaaaaa!!!!!!! &lt;at&gt;KingJames is thats your day...</td>\n",
       "      <td>0.985658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>How 'bout that Kammy Driver? My rookie season ...</td>\n",
       "      <td>0.985556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>Mike &amp; Mike at 10am EST</td>\n",
       "      <td>0.985459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>I put in Double-1's. 2-at-ATS from T. Wilson a...</td>\n",
       "      <td>0.984983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>also, despite your tirade, gbjr is NOT doing i...</td>\n",
       "      <td>0.984797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet     score\n",
       "378   When Jesus Missing in Samoa, neither HBCU, col...  1.000000\n",
       "979   I'm about to appear on REGRET radio ppl. Call ...  1.000000\n",
       "942   Jesus. Cowboys have the best offense in footba...  1.000000\n",
       "1017  Oh God, Oh Jesus Do I Sound So sad. This is li...  1.000000\n",
       "813   I wanted <at>TinyQuinn to win the Heisman befo...  1.000000\n",
       "...                                                 ...       ...\n",
       "120   Haaaaaa!!!!!!! <at>KingJames is thats your day...  0.985658\n",
       "169   How 'bout that Kammy Driver? My rookie season ...  0.985556\n",
       "1008                            Mike & Mike at 10am EST  0.985459\n",
       "113   I put in Double-1's. 2-at-ATS from T. Wilson a...  0.984983\n",
       "633   also, despite your tirade, gbjr is NOT doing i...  0.984797\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reference=[tweet.split() for tweet in sas['full_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate='Chris Bosh and the Toronto Raptors seem to have a lot to say about me today Check out my response at <url>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu(reference,candidate.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in top_100['tweet']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
